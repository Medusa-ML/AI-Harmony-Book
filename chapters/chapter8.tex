\setchapterpreamble[u]{\margintoc}
\chapter{Unplugging Skynet}
\labch{intro}

\textit{"The second requirement of goal-misalignment risk is that an intelligent machine can commandeer the Earth's resources to pursue its goals, or in other ways prevent us from stopping it... We have similar concerns with humans. This is why no single person or entity can control the entire internet and why we require multiple people to launch a nuclear missile. Intelligent machines will not develop misaligned goals unless we go to great lengths to endow them with that ability. Even if they did, no machine can commandeer the world's resources unless we let it. We don't let a single human, or even a small number of humans, control the world's resources. We need to be similarly careful with machines."} Jeff Hawkins, 2022 \cite{hawkins_2022}

\section{AI and Human Safety}

\section{Useful Incompatability}

It's a feature not a bug that no single comupter can control all others, AKA Security by Obscurity

\section{Checks and Balances}

\section{Free-Rider Problems}

I can steal your AI quite easily from outputs

\section{When You Can't Tell The Difference}

Talk about Taleb's aphorisms "Another definition of modernity: conversations can be more and more completely reconstructed with clips from other conversations taking place at the same time on the planet.", "You are alive in inverse proportion to the density of cliches in your writing." 

\section{Sucker Traps}

"The sucker's trap is when you focus on what you know and what others don't know, rather than the reverse."

\section{Dead Inside}

"If you know, in the morning, what your day looks like with any precision you are a little bit dead - the more precision the more dead you are."
