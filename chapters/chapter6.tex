\setchapterpreamble[u]{\margintoc}
\chapter{Unplugging Skynet}
\labch{skynet}

\textit{"The second requirement of goal-misalignment risk is that an intelligent machine can commandeer the Earth's resources to pursue its goals, or in other ways prevent us from stopping it... We have similar concerns with humans. This is why no single person or entity can control the entire internet and why we require multiple people to launch a nuclear missile. Intelligent machines will not develop misaligned goals unless we go to great lengths to endow them with that ability. Even if they did, no machine can commandeer the world's resources unless we let it. We don't let a single human, or even a small number of humans, control the world's resources. We need to be similarly careful with machines."} Jeff Hawkins, 2022 \cite{hawkins2022}

\section{AI and Human Safety}

\textit{"First World War was known as "the war to end all wars," although some historians now argue it didn't. But it was the first high-tech war, with aeroplanes, machine guns and tanks all rising up to fight the human beings that made them. Despite having no beliefs or ideology or hearts or souls, the killing machines were victorious. The final score was weaponry 20 million, mankind nil."} Cunk On Earth Season 1 Espisode 3 %TODO Cite properly

\section{Useful Incompatability}

It's a feature not a bug that no single comupter can control all others, AKA Security by Obscurity

\section{Checks and Balances}

\url{https://www.acm.org/media-center/2023/january/techbrief-safer-algorithmic-systems}
