\setchapterpreamble[u]{\margintoc}
\chapter{Generating Art: Avante-Garde or Derivative?}
\labch{intro}

\textit{"(Traditional) search engines are databases, organized collections of data that can be stored, updated, and retrieved at will. (Traditional) search engines are indexes. a form of database, that connect things like keywords to URLs; they can be swiftly updated, incrementally, bit by bit (as when you update a phone number in the database that holds your contacts).}

\textit{Large language models do something very different: they are not databases; they are text predictors, turbocharged versions of autocomplete. Fundamentally, what they learn are relationships between bits of text, like words, phrases, even whole sentences. And they use those relationships to predict other bits of text. And then they do something almost magical: they paraphrase those bits of texts, almost like a thesaurus but much much better. But as they do so, as they glom stuff together, something often gets lost in translation: which bits of text do and do not truly belong together."} Gary Marcus, 2023 \cite{marcus_2023}

\section{Predictive Keyboards}

\section{GPT On A Napkin}

Discuss this \sidenote{\href{https://dugas.ch/artificial_curiosity/GPT_architecture.html}{GPT On A Napkin}}

\section{Compress The World's Achievements Into One Database}


Lossy lookup of data, see how close you get to creating famous artworks or wikipedia pages?

Talk about AI upscaling and AI as lossy compression. we stored the entire corpus of human knowledge, but AI retrieves it in a silly way.

\section{Upscaling What Is Lost}

How to leverage this stuff.

\section{Who Owns This Stuff Anyway?}

Discuss FSF and Copilot, lawsuits.

\section{Use Critical Thinking to Become A Critic}

Talk about ChatGPT, deterministic vs probabalistic and Thomas Hobbes \sidenote{\href{https://stratechery.com/2022/ai-homework/}{AI Homework}}


