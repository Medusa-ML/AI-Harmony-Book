\setchapterpreamble[u]{\margintoc}
\chapter{Unplugging Skynet}
\labch{skynet}

\textit{"The second requirement of goal-misalignment risk is that an intelligent machine can commandeer the Earth's resources to pursue its goals, or in other ways prevent us from stopping it... We have similar concerns with humans. This is why no single person or entity can control the entire internet and why we require multiple people to launch a nuclear missile. Intelligent machines will not develop misaligned goals unless we go to great lengths to endow them with that ability. Even if they did, no machine can commandeer the world's resources unless we let it. We don't let a single human, or even a small number of humans, control the world's resources. We need to be similarly careful with machines." - Jeff Hawkins, 2022 \cite{hawkins2022}}

\section{Landmines Everywhere}

As we explore the potential of artificial intelligence in the realm of warfare, it is crucial to approach the topic of autonomous weapons with a healthy dose of skepticism. To fully grasp the inherent risks of these weapons, we need look no further than the history of landmines. These indiscriminate, uncontrollable devices should serve as a stark reminder of the potential pitfalls associated with the development and deployment of autonomous weaponry.

Landmines have long been a staple of military strategy, yet their consequences continue to plague countless communities around the world. Once deployed, landmines cannot differentiate between friend or foe, soldier or civilian. They lie dormant, waiting to unleash their destructive force on unsuspecting victims, often long after the conflict has ceased. This lack of control and the resulting collateral damage make landmines a morally and ethically questionable choice in modern warfare.

When examining the prospect of advanced AI-powered autonomous weapons, we must confront the reality that these systems may ultimately share the same fundamental flaw as landmines: the lack of control. While it is true that AI technology has the potential to drastically reduce human casualties and improve targeting precision, it is crucial to recognize the potential for these weapons to become indiscriminate and uncontrollable, much like their landmine predecessors. Once released into the world, these autonomous systems may wreak havoc beyond their intended targets and pose a significant threat to innocent lives.

The dystopian vision of a "Skynet" scenario, as popularized by the Terminator series, should remain firmly in the realm of science fiction. It is not only an unrealistic portrayal of AI development but also a dangerously misguided idea to pursue. Instead of fixating on a sensationalized and unlikely outcome, we must focus our attention on understanding the true consequences and ethical implications of AI-powered weaponry. We must recognize that creating uncontrollable, indiscriminate weapons is neither wise nor responsible.

As we venture further into the domain of AI and autonomous weapons, let us heed the lessons from landmines and strive to build a future where technology serves to protect and preserve, rather than to destroy indiscriminately. By approaching this complex issue with an informed and critical perspective, we can work together to ensure that the perils of the past are not repeated and that we create a more conscientious and responsible future for AI-powered warfare.


\section{Human Responsibility in Weaponized AI}

Synthetic Media and the Impact on AI \cite{syntheticmedia}

\section{The Inherent Flaws in Asimov's Three Laws of Robotics}

\begin{itemize}
    \item\textit{First Law: A robot may not injure a human being or, through inaction, allow a human being to come to harm.}
    \item\textit{Second Law: A robot must obey the orders given it by human beings except where such orders would conflict with the First Law.}
    \item\textit{Third Law: A robot must protect its own existence as long as such protection does not conflict with the First or Second Law.}
\end{itemize} 
\textit{Asimov's Three Laws of Robotics}

The Importance of Consent

The Value of Security by Obscurity

\section{AI in Warfare: Challenges and Concerns}

\textit{"First World War was known as "the war to end all wars," although some historians now argue it didn't. But it was the first high-tech war, with aeroplanes, machine guns and tanks all rising up to fight the human beings that made them. Despite having no beliefs or ideology or hearts or souls, the killing machines were victorious. The final score was weaponry 20 million, mankind nil."} Cunk On Earth Season 1 Espisode 3 \cite{cunkonearth}

AI Warfare \cite{aiwarfare}

\section{The Role of Training Data in AI Decision-Making}

The Limits and Risks of Deep Learning Models

\section{Ensuring Safer Algorithmic Systems}

\cite{saferalgorithmicsystems}

The Challenges of Interpretability and Transparency

The Impact of Biased Training Data

The Problem of Overfitting

Vulnerability to Adversarial Attacks

