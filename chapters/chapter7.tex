\setchapterpreamble[u]{\margintoc}
\chapter{Revolutionary for Whom?}
\labch{intro}

\textit{"The inhabitant of London could order by telephone, sipping his morning tea in bed, the various products of the whole earth -- he could at the same time and by the same means adventure his wealth in the natural resources and new enterprise of any quarter of the world -- he could secure forthwith, if he wished, cheap and comfortable means of transit to any country or climate without passport or other formality."} John Maynard Keynes, 1920 \cite{Keynes2012}

\section{The Battle of the Assistants}

Butler vs Indian Virtual Assistant vs Siri

\section{Employees That Are Better Than You}

Respond directly to Jon Krohn's TED talk about monkeys being dumber than us... what about construction equipmenth that's stronger than us physically, or racism/eugenics people that are dumber than us \sidecite{KrohnTED}

\section{Slow on the Uptake}

\url{https://www.economist.com/finance-and-economics/2023/02/02/the-ai-boom-lessons-from-history} talk about historical perspective of technological change. Counter the narrative of "fastest tech to 1 million users" for ChatGPT.

\section{Free-Rider Problems}

I can steal your AI quite easily from outputs

\section{When You Can't Tell The Difference}

Talk about Taleb's aphorisms "Another definition of modernity: conversations can be more and more completely reconstructed with clips from other conversations taking place at the same time on the planet.", "You are alive in inverse proportion to the density of cliches in your writing."

\section{Sucker Traps}

\textit{"(Traditional) search engines are databases, organized collections of data that can be stored, updated, and retrieved at will. (Traditional) search engines are indexes. a form of database, that connect things like keywords to URLs; they can be swiftly updated, incrementally, bit by bit (as when you update a phone number in the database that holds your contacts).}

\textit{Large language models do something very different: they are not databases; they are text predictors, turbocharged versions of autocomplete. Fundamentally, what they learn are relationships between bits of text, like words, phrases, even whole sentences. And they use those relationships to predict other bits of text. And then they do something almost magical: they paraphrase those bits of texts, almost like a thesaurus but much much better. But as they do so, as they glom stuff together, something often gets lost in translation: which bits of text do and do not truly belong together."} Gary Marcus, 2023 \cite{marcus2023}

"The sucker's trap is when you focus on what you know and what others don't know, rather than the reverse."

\section{Dead Inside}

"If you know, in the morning, what your day looks like with any precision you are a little bit dead - the more precision the more dead you are."

\section{This Book is a Case Study}

Talk about "organic content" market.
