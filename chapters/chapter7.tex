\setchapterpreamble[u]{\margintoc}
\chapter{Unplugging Skynet}
\labch{skynet}

\textit{"The second requirement of goal-misalignment risk is that an intelligent machine can commandeer the Earth's resources to pursue its goals, or in other ways prevent us from stopping it... We have similar concerns with humans. This is why no single person or entity can control the entire internet and why we require multiple people to launch a nuclear missile. Intelligent machines will not develop misaligned goals unless we go to great lengths to endow them with that ability. Even if they did, no machine can commandeer the world's resources unless we let it. We don't let a single human, or even a small number of humans, control the world's resources. We need to be similarly careful with machines." - Jeff Hawkins, 2022 \cite{hawkins2022}}

\section{The Perils of Early Autonomous Weapons}
\begin{itemize}
\item Landmines
\item Sentry guns
\item Cruise missiles
\item Unmanned ground vehicles (UGVs)
\end{itemize}

\section{The Fallacy of Autonomous Weapons Acting Independently}

Debunking the Myth of Uncontrolled AI

\section{Human Responsibility in Weaponized AI}

Synthetic Media and the Impact on AI \cite{syntheticmedia}

\section{The Inherent Flaws in Asimov's Three Laws of Robotics}

The Importance of Consent

The Value of Security by Obscurity

\section{AI in Warfare: Challenges and Concerns}

\textit{"First World War was known as "the war to end all wars," although some historians now argue it didn't. But it was the first high-tech war, with aeroplanes, machine guns and tanks all rising up to fight the human beings that made them. Despite having no beliefs or ideology or hearts or souls, the killing machines were victorious. The final score was weaponry 20 million, mankind nil."} Cunk On Earth Season 1 Espisode 3 \cite{cunkonearth}

AI Warfare \cite{aiwarfare}

\section{The Role of Training Data in AI Decision-Making}

The Limits and Risks of Deep Learning Models

\section{Ensuring Safer Algorithmic Systems}
\cite{saferalgorithmicsystems}

The Challenges of Interpretability and Transparency

The Impact of Biased Training Data

The Problem of Overfitting

Vulnerability to Adversarial Attacks

